{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "5RWmI06ynebb"
      ],
      "authorship_tag": "ABX9TyMbpLmdLttDOtlzdLehA1f4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassaku12/manabiDX2025/blob/main/%E6%BC%94%E7%BF%9203%EF%BC%88%E8%A9%A6%E3%81%99%E7%94%A8%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Š"
      ],
      "metadata": {
        "id": "5RWmI06ynebb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2u0gVJvouG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265b2e27-ee3d-4977-dff2-7e1ba02be63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ã¾ãšã¯Googleãƒ‰ãƒ©ã‚¤ãƒ–ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# japanize-matplotlibã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (å®Ÿè¡Œç’°å¢ƒã«æœªå°å…¥ã®å ´åˆ)\n",
        "!pip install japanize-matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCJXCkY4EUNg",
        "outputId": "1ac8bc75-58c3-4581-9485-780e3c61327d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting japanize-matplotlib\n",
            "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/4.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/4.1 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from japanize-matplotlib) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->japanize-matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.17.0)\n",
            "Building wheels for collected packages: japanize-matplotlib\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120257 sha256=f507c6abc2039c2703f1c7197195b96b7aadfb9a060b3cb0006bc9fd38bcff92\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/a1/71/b8faeb93276fed10edffcca20746f1ef6f8d9e071eee8425fc\n",
            "Successfully built japanize-matplotlib\n",
            "Installing collected packages: japanize-matplotlib\n",
            "Successfully installed japanize-matplotlib-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import japanize_matplotlib\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier # ã“ã®è¡Œã‚’è¿½åŠ \n",
        "from sklearn.linear_model import LogisticRegression # ã“ã®è¡Œã‚’è¿½åŠ \n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score # ã“ã®è¡Œã‚’è¿½åŠ \n",
        "from sklearn.preprocessing import StandardScaler # ã“ã®è¡Œã‚’è¿½åŠ \n",
        "from sklearn.model_selection import cross_val_score # ã“ã®è¡Œã‚’è¿½åŠ \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "o6mDl66NEpqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/ãƒãƒŠãƒ’ã‚™DX'"
      ],
      "metadata": {
        "id": "PB_duKNHFzL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿\n",
        "train_df = pd.read_csv(base_dir + '/train.csv')\n",
        "\n",
        "# è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿\n",
        "test_df = pd.read_csv(base_dir + '/test.csv')\n",
        "\n",
        "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼è¦‹æœ¬\n",
        "submission_df = pd.read_csv(base_dir + '/sample_submit.csv', header=None)\n",
        "\n",
        "# é¡§å®¢ã®å±æ€§ã‚„æŠ•è³‡çµŒé¨“ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿\n",
        "assessment_df = pd.read_csv(base_dir + '/é©åˆæ€§åˆ¤å®šã‚·ãƒ¼ãƒˆä¸€è¦§è¡¨.csv')"
      ],
      "metadata": {
        "id": "T2oQ0Gv7GEQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆã™ã¹ã¦ã‚’é–¢æ•°ã§çµ±ä¸€ï¼‰"
      ],
      "metadata": {
        "id": "AhZBUc-aJyJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# é¡§å®¢IDã«é‡è¤‡ãŒã‚ã‚‹assessment_dfã‹ã‚‰å„é¡§å®¢æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’æ®‹ã™\n",
        "assessment_df['å–å¼•æ—¥'] = pd.to_datetime(assessment_df['å–å¼•æ—¥'])\n",
        "assessment_df_latest = assessment_df.sort_values(['é¡§å®¢ID', 'å–å¼•æ—¥']).drop_duplicates(subset='é¡§å®¢ID', keep='last')\n",
        "assessment_df_selected = assessment_df_latest[['é¡§å®¢ID', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰']]"
      ],
      "metadata": {
        "id": "geqgG3BxJ0I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df ã¨ test_df ã«é¡§å®¢ã®å±æ€§æƒ…å ±ã‚’çµåˆ\n",
        "train_df = pd.merge(train_df, assessment_df_selected, on='é¡§å®¢ID', how='left')\n",
        "test_df = pd.merge(test_df, assessment_df_selected, on='é¡§å®¢ID', how='left')"
      ],
      "metadata": {
        "id": "xs6QOxbEKTNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æ¬ æå€¤ã‚’è£œå®Œ\n",
        "train_df['é¡§å®¢å¹´é½¢'] = train_df['é¡§å®¢å¹´é½¢'].fillna(train_df['é¡§å®¢å¹´é½¢'].mean())\n",
        "test_df['é¡§å®¢å¹´é½¢'] = test_df['é¡§å®¢å¹´é½¢'].fillna(test_df['é¡§å®¢å¹´é½¢'].mean())\n",
        "train_df['æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰'] = train_df['æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰'].fillna(0)\n",
        "test_df['æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰'] = test_df['æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰'].fillna(0)"
      ],
      "metadata": {
        "id": "TheHXUiyKVQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# åŸºæº–å¹´æœˆã‹ã‚‰å¹´ã¨æœˆã‚’æŠ½å‡º\n",
        "train_df['year'] = train_df['åŸºæº–å¹´æœˆ'].str.split('-').str[0].astype(int)\n",
        "train_df['month'] = train_df['åŸºæº–å¹´æœˆ'].str.split('-').str[1].astype(int)\n",
        "test_df['year'] = test_df['åŸºæº–å¹´æœˆ'].str.split('-').str[0].astype(int)\n",
        "test_df['month'] = test_df['åŸºæº–å¹´æœˆ'].str.split('-').str[1].astype(int)"
      ],
      "metadata": {
        "id": "cwCZR8nTKYEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trend_features(df):\n",
        "    \"\"\"é¡§å®¢ã®æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç‰¹å¾´é‡åŒ–\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # é¡§å®¢ã”ã¨ã®æ™‚ç³»åˆ—çµ±è¨ˆï¼ˆéå»ã‹ã‚‰ç¾åœ¨ã¸ã®å¤‰åŒ–ï¼‰\n",
        "    customer_trends = df.groupby('é¡§å®¢ID').agg({\n",
        "        'æ™‚ä¾¡ä¾¡é¡': ['first', 'last', 'std'],  # æœ€åˆãƒ»æœ€å¾Œãƒ»å¤‰å‹•\n",
        "        'è³‡ç”£è¦æ¨¡': ['first', 'last', 'std'],\n",
        "        'è©•ä¾¡æç›Š': ['first', 'last', 'std'],\n",
        "        'åŸºæº–å¹´æœˆ': ['count', 'nunique']  # è¨˜éŒ²æ•°ãƒ»æœŸé–“æ•°\n",
        "    }).fillna(0)\n",
        "\n",
        "    # ã‚«ãƒ©ãƒ åã‚’å¹³å¦åŒ–\n",
        "    customer_trends.columns = ['_'.join(col) for col in customer_trends.columns]\n",
        "\n",
        "    # ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ã‚’è¨ˆç®—\n",
        "    customer_trends['æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡'] = (\n",
        "        (customer_trends['æ™‚ä¾¡ä¾¡é¡_last'] - customer_trends['æ™‚ä¾¡ä¾¡é¡_first']) /\n",
        "        (customer_trends['æ™‚ä¾¡ä¾¡é¡_first'] + 1)\n",
        "    )\n",
        "    customer_trends['è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡'] = (\n",
        "        (customer_trends['è³‡ç”£è¦æ¨¡_last'] - customer_trends['è³‡ç”£è¦æ¨¡_first']) /\n",
        "        (customer_trends['è³‡ç”£è¦æ¨¡_first'] + 1)\n",
        "    )\n",
        "    customer_trends['æç›Š_å¤‰åŒ–ç‡'] = (\n",
        "        (customer_trends['è©•ä¾¡æç›Š_last'] - customer_trends['è©•ä¾¡æç›Š_first']) /\n",
        "        (abs(customer_trends['è©•ä¾¡æç›Š_first']) + 1)\n",
        "    )\n",
        "\n",
        "    # å¤‰å‹•æ€§ç‰¹å¾´é‡\n",
        "    customer_trends['æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°'] = (\n",
        "        customer_trends['æ™‚ä¾¡ä¾¡é¡_std'] / (customer_trends['æ™‚ä¾¡ä¾¡é¡_last'] + 1)\n",
        "    )\n",
        "    customer_trends['è³‡ç”£_å®‰å®šæ€§'] = (\n",
        "        customer_trends['è³‡ç”£è¦æ¨¡_std'] / (customer_trends['è³‡ç”£è¦æ¨¡_last'] + 1)\n",
        "    )\n",
        "\n",
        "    # å…ƒãƒ‡ãƒ¼ã‚¿ã«çµåˆ\n",
        "    df = df.merge(customer_trends, left_on='é¡§å®¢ID', right_index=True, how='left')\n",
        "\n",
        "    # æ¬ æå€¤å‡¦ç†\n",
        "    trend_cols = [col for col in df.columns if any(x in col for x in ['å¤‰åŒ–ç‡', 'å¤‰å‹•ä¿‚æ•°', 'å®‰å®šæ€§'])]\n",
        "    for col in trend_cols:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "lW_5t208Ka2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_trading_behavior_features(df, base_dir):\n",
        "    \"\"\"ç´„å®šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹å¾´é‡ã‚’ä½œæˆ\"\"\"\n",
        "    try:\n",
        "        # ç´„å®šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
        "        trading_df = pd.read_csv(base_dir + '/ç´„å®šãƒ‡ãƒ¼ã‚¿ä¸€è¦§è¡¨.csv')\n",
        "        trading_df['å–å¼•æ—¥'] = pd.to_datetime(trading_df['å–å¼•æ—¥'])\n",
        "\n",
        "        # 2021å¹´11æœˆ30æ—¥ä»¥å‰ã®å–å¼•\n",
        "        past_trading = trading_df[trading_df['å–å¼•æ—¥'] <= '2021-11-30']\n",
        "\n",
        "        # ã€é‡è¦ã€‘é¡§å®¢ã®å–å¼•è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\n",
        "        customer_behavior = past_trading.groupby('é¡§å®¢ID').agg({\n",
        "            'å–å¾—ä¾¡é¡': ['count', 'mean', 'std', 'sum'],\n",
        "            'å£²å´æç›Š': ['sum', 'mean', 'std', 'count'],\n",
        "            'å„Ÿé‚„æç›Š': ['sum', 'count'],\n",
        "            'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°': ['mean', 'sum'],\n",
        "            'ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½': ['mean', 'sum'],\n",
        "            'ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½': ['mean', 'sum'],\n",
        "            'å–å¼•æ—¥': [lambda x: (x.max() - x.min()).days,  # å–å¼•æœŸé–“\n",
        "                     lambda x: x.nunique(),  # å–å¼•æ—¥æ•°\n",
        "                     'count']  # ç·å–å¼•å›æ•°\n",
        "        }).fillna(0)\n",
        "\n",
        "        # ã‚«ãƒ©ãƒ åæ•´ç†\n",
        "        customer_behavior.columns = [f'å–å¼•_{col[0]}_{col[1]}' if isinstance(col, tuple) else f'å–å¼•_{col}'\n",
        "                                   for col in customer_behavior.columns]\n",
        "\n",
        "        # æ”¹å\n",
        "        rename_dict = {\n",
        "            'å–å¼•_å–å¼•æ—¥_<lambda_0>': 'å–å¼•æœŸé–“_æ—¥æ•°',\n",
        "            'å–å¼•_å–å¼•æ—¥_<lambda_1>': 'å–å¼•æ—¥æ•°',\n",
        "            'å–å¼•_å–å¼•æ—¥_count': 'ç·å–å¼•å›æ•°'\n",
        "        }\n",
        "        customer_behavior.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "        # ã€é‡è¦ã€‘æ´¾ç”Ÿç‰¹å¾´é‡ï¼ˆæŠ•è³‡æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\n",
        "        # Note: 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡'\n",
        "        # These names do not match the column names generated above.\n",
        "        # Let's create features that match the expected names.\n",
        "        customer_behavior['éå»å–å¼•å›æ•°'] = customer_behavior['ç·å–å¼•å›æ•°'] # Assuming this is the same as total transaction count\n",
        "        customer_behavior['éå»ç´¯ç©æç›Š'] = customer_behavior['å–å¼•_å£²å´æç›Š_sum'] + customer_behavior['å–å¼•_å„Ÿé‚„æç›Š_sum'] # Sum of sell and redemption profit/loss\n",
        "        customer_behavior['æŠ•è³‡æˆåŠŸä½“é¨“'] = (customer_behavior['éå»ç´¯ç©æç›Š'] > 0).astype(int) # Flag for positive cumulative profit/loss\n",
        "        customer_behavior['é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡'] = df.groupby('é¡§å®¢ID')['æ™‚ä¾¡ä¾¡é¡'].mean() # Need to calculate from the original df\n",
        "        customer_behavior['é¡§å®¢è¨˜éŒ²æ•°'] = df.groupby('é¡§å®¢ID').size() # Need to calculate from the original df\n",
        "        customer_behavior['é¡§å®¢è³‡ç”£å¤‰å‹•'] = df.groupby('é¡§å®¢ID')['æ™‚ä¾¡ä¾¡é¡'].std().fillna(0) # Need to calculate from the original df\n",
        "        # 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡' requires overall market context, which is not directly available here.\n",
        "        # Let's create a placeholder or an approximation.\n",
        "        # A simple approximation could be a customer's average market value relative to the overall average.\n",
        "        overall_avg_market_value = df['æ™‚ä¾¡ä¾¡é¡'].mean()\n",
        "        customer_behavior['ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡'] = (customer_behavior['é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡'] / (overall_avg_market_value + 1)).fillna(0)\n",
        "\n",
        "\n",
        "        customer_behavior['å¹³å‡åˆ©ç›Šç‡'] = (\n",
        "            customer_behavior['å–å¼•_å£²å´æç›Š_sum'] /\n",
        "            (customer_behavior['å–å¼•_å–å¾—ä¾¡é¡_sum'] + 1)\n",
        "        )\n",
        "        customer_behavior['å–å¼•é »åº¦'] = (\n",
        "            customer_behavior['ç·å–å¼•å›æ•°'] /\n",
        "            (customer_behavior['å–å¼•æœŸé–“_æ—¥æ•°'] + 1) * 365\n",
        "        )\n",
        "        customer_behavior['æ•°å­—æ´»ç”¨åº¦'] = customer_behavior['å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean'] # Assuming 'ãƒ‡ã‚¸ã‚¿ãƒ«æ´»ç”¨åº¦' is a typo and should be 'æ•°å­—æ´»ç”¨åº¦' based on 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°'\n",
        "        customer_behavior['ãƒªã‚¹ã‚¯ç®¡ç†åº¦'] = (\n",
        "            customer_behavior['å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean'] +\n",
        "            customer_behavior['å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean']\n",
        "        ) / 2\n",
        "\n",
        "        # ã€é‡è¦ã€‘æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—åˆ†é¡\n",
        "        customer_behavior['æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—'] = 'ãã®ä»–'\n",
        "\n",
        "        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æŠ•è³‡å®¶ï¼šé »ç¹ã«å–å¼•ã€æˆåŠŸç‡é«˜ã„\n",
        "        active_mask = (\n",
        "            (customer_behavior['ç·å–å¼•å›æ•°'] > customer_behavior['ç·å–å¼•å›æ•°'].quantile(0.7)) &\n",
        "            (customer_behavior['æŠ•è³‡æˆåŠŸä½“é¨“'] > 0) # Using the newly created feature\n",
        "        )\n",
        "        customer_behavior.loc[active_mask, 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—'] = 'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–'\n",
        "\n",
        "        # æ…é‡æŠ•è³‡å®¶ï¼šãƒªã‚¹ã‚¯ç®¡ç†é‡è¦–\n",
        "        careful_mask = (\n",
        "            customer_behavior['ãƒªã‚¹ã‚¯ç®¡ç†åº¦'] > 0.5\n",
        "        )\n",
        "        customer_behavior.loc[careful_mask, 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—'] = 'æ…é‡'\n",
        "\n",
        "        # ãƒ‡ã‚¸ã‚¿ãƒ«æŠ•è³‡å®¶ï¼šã‚ªãƒ³ãƒ©ã‚¤ãƒ³ä¸­å¿ƒ\n",
        "        digital_mask = (\n",
        "            customer_behavior['æ•°å­—æ´»ç”¨åº¦'] > 0.5 # Using the corrected name\n",
        "        )\n",
        "        customer_behavior.loc[digital_mask, 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—'] = 'ãƒ‡ã‚¸ã‚¿ãƒ«'\n",
        "\n",
        "        print(\"Debug: customer_behavior columns before merge:\", customer_behavior.columns.tolist())\n",
        "        print(\"Debug: customer_behavior shape before merge:\", customer_behavior.shape)\n",
        "        print(\"Debug: df columns before merge:\", df.columns.tolist())\n",
        "        print(\"Debug: df shape before merge:\", df.shape)\n",
        "\n",
        "\n",
        "        # å…ƒãƒ‡ãƒ¼ã‚¿ã«çµåˆ\n",
        "        df = df.merge(customer_behavior, left_on='é¡§å®¢ID', right_index=True, how='left')\n",
        "\n",
        "        print(\"Debug: df columns after merge:\", df.columns.tolist())\n",
        "        print(\"Debug: df shape after merge:\", df.shape)\n",
        "\n",
        "\n",
        "        # æ¬ æå€¤å‡¦ç†\n",
        "        # Update the list of trading_cols to include the newly created features\n",
        "        trading_cols = [col for col in df.columns if col.startswith('å–å¼•_') or\n",
        "                       col in ['éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡',\n",
        "                               'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡',\n",
        "                               'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—']]\n",
        "\n",
        "        for col in trading_cols:\n",
        "            if col != 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—':\n",
        "                df[col] = df[col].fillna(0)\n",
        "            else:\n",
        "                df[col] = df[col].fillna('ãã®ä»–')\n",
        "\n",
        "        print(\"ğŸ“ˆ å–å¼•è¡Œå‹•ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¾ã—ãŸ\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ å–å¼•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ç‰¹å¾´é‡ä½œæˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "        # ãƒ€ãƒŸãƒ¼ç‰¹å¾´é‡\n",
        "        # Ensure all expected features are added as dummy columns in case of error\n",
        "        dummy_cols = ['éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡',\n",
        "                      'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡',\n",
        "                      'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—']\n",
        "        for col in dummy_cols:\n",
        "            if col not in df.columns:\n",
        "                if col == 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—':\n",
        "                    df[col] = 'ãã®ä»–'\n",
        "                else:\n",
        "                    df[col] = 0\n",
        "        return df"
      ],
      "metadata": {
        "id": "kSB2M-xmOROI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ã€æ”¹å–„3ã€‘ä½æ‰€ãƒ»åœ°åŸŸç‰¹å¾´é‡ã®å¼·åŒ–\n",
        "def create_regional_features(df):\n",
        "    \"\"\"ä½æ‰€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åœ°åŸŸç‰¹æ€§ã‚’æŠ½å‡º\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # ä½æ‰€ã‚³ãƒ¼ãƒ‰åˆ¥ã®è©³ç´°çµ±è¨ˆ\n",
        "    if 'y' in df.columns:\n",
        "        regional_stats = df.groupby('ä½æ‰€ã‚³ãƒ¼ãƒ‰').agg({\n",
        "            'y': ['mean', 'sum', 'count'],\n",
        "            'æ™‚ä¾¡ä¾¡é¡': ['mean', 'median', 'std'],\n",
        "            'è³‡ç”£è¦æ¨¡': ['mean', 'median'],\n",
        "            'é¡§å®¢å¹´é½¢': ['mean', 'std'],\n",
        "            'æŠ•è³‡æ–¹é‡': 'mean',\n",
        "            'è©•ä¾¡æç›Š': ['mean', 'std']\n",
        "        }).fillna(0)\n",
        "\n",
        "        regional_stats.columns = [f'åœ°åŸŸ_{col[0]}_{col[1]}' for col in regional_stats.columns]\n",
        "\n",
        "        # åœ°åŸŸç‰¹æ€§ã®æ´¾ç”Ÿç‰¹å¾´é‡\n",
        "        regional_stats['åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦'] = regional_stats['åœ°åŸŸ_y_mean']\n",
        "        regional_stats['åœ°åŸŸ_å¯Œè£•åº¦'] = regional_stats['åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean']\n",
        "        regional_stats['åœ°åŸŸ_å®‰å®šåº¦'] = 1 / (regional_stats['åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std'] + 1)\n",
        "        regional_stats['åœ°åŸŸ_æˆç†Ÿåº¦'] = regional_stats['åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean']\n",
        "\n",
        "        # åœ°åŸŸãƒ©ãƒ³ã‚­ãƒ³ã‚°\n",
        "        regional_stats['åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½'] = regional_stats['åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦'].rank(pct=True)\n",
        "        regional_stats['åœ°åŸŸ_å¯Œè£•åº¦_é †ä½'] = regional_stats['åœ°åŸŸ_å¯Œè£•åº¦'].rank(pct=True)\n",
        "\n",
        "        df = df.merge(regional_stats, left_on='ä½æ‰€ã‚³ãƒ¼ãƒ‰', right_index=True, how='left')\n",
        "\n",
        "        # æ¬ æå€¤å‡¦ç†\n",
        "        regional_cols = [col for col in df.columns if col.startswith('åœ°åŸŸ_')]\n",
        "        for col in regional_cols:\n",
        "            df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "pIB2wLpDOd-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_advanced_features_v2(df, base_dir=None):\n",
        "    \"\"\"AUCå‘ä¸Šã«ç‰¹åŒ–ã—ãŸé«˜åº¦ãªç‰¹å¾´é‡ä½œæˆ\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # åŸºæœ¬ç‰¹å¾´é‡\n",
        "    df['è³‡ç”£è¦æ¨¡'] = df['å–å¾—ä¾¡é¡'] + df['æ™‚ä¾¡ä¾¡é¡']\n",
        "    df['å«ã¿æç›Šç‡'] = np.where(df['å–å¾—ä¾¡é¡'] != 0,\n",
        "                                 (df['æ™‚ä¾¡ä¾¡é¡'] - df['å–å¾—ä¾¡é¡']) / df['å–å¾—ä¾¡é¡'], 0)\n",
        "    df['è©•ä¾¡å€ç‡'] = np.where(df['å–å¾—ä¾¡é¡'] != 0, df['æ™‚ä¾¡ä¾¡é¡'] / df['å–å¾—ä¾¡é¡'], 1)\n",
        "\n",
        "    # æ™‚ç³»åˆ—\n",
        "    df['quarter'] = ((df['month'] - 1) // 3) + 1\n",
        "    df['is_quarter_end'] = df['month'].isin([3, 6, 9, 12]).astype(int)\n",
        "    df['age_group'] = pd.cut(df['é¡§å®¢å¹´é½¢'], bins=[0, 50, 100], labels=['young', 'senior'])\n",
        "\n",
        "    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç‰¹å¾´é‡\n",
        "    df['æ™‚ä¾¡ä¾¡é¡_é †ä½'] = df['æ™‚ä¾¡ä¾¡é¡'].rank(pct=True)\n",
        "    df['è³‡ç”£è¦æ¨¡_é †ä½'] = df['è³‡ç”£è¦æ¨¡'].rank(pct=True)\n",
        "    df['è©•ä¾¡æç›Š_é †ä½'] = df['è©•ä¾¡æç›Š'].rank(pct=True)\n",
        "\n",
        "    # ç›¸äº’ä½œç”¨\n",
        "    df['å¹´é½¢Ã—è³‡ç”£è¦æ¨¡'] = df['é¡§å®¢å¹´é½¢'] * df['è³‡ç”£è¦æ¨¡']\n",
        "    df['æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡'] = df['æŠ•è³‡æ–¹é‡'] * df['æ™‚ä¾¡ä¾¡é¡']\n",
        "\n",
        "    # ã€æ–°è¦ã€‘ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡\n",
        "    df = create_trend_features(df)\n",
        "    print(\"ğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ã‚’è¿½åŠ \")\n",
        "\n",
        "    # ã€æ–°è¦ã€‘å–å¼•è¡Œå‹•ç‰¹å¾´é‡\n",
        "    if base_dir:\n",
        "        df = create_trading_behavior_features(df, base_dir)\n",
        "\n",
        "    # ã€æ–°è¦ã€‘åœ°åŸŸç‰¹å¾´é‡\n",
        "    df = create_regional_features(df)\n",
        "    print(\"ğŸ—ºï¸ åœ°åŸŸç‰¹å¾´é‡ã‚’è¿½åŠ \")\n",
        "\n",
        "    # åŸºæœ¬ãƒ•ãƒ©ã‚°\n",
        "    df['é«˜è³‡ç”£ãƒ•ãƒ©ã‚°'] = (df['è³‡ç”£è¦æ¨¡'] > df['è³‡ç”£è¦æ¨¡'].quantile(0.8)).astype(int)\n",
        "    df['å«ã¿æãƒ•ãƒ©ã‚°'] = (df['è©•ä¾¡æç›Š'] < 0).astype(int)\n",
        "    df['ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°'] = (df['é¡§å®¢å¹´é½¢'] >= 65).astype(int)\n",
        "    df['æ ªå¼çµŒé¨“ã‚ã‚Š'] = (df['æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰'] > 0).astype(int)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "WVK5Oh1qKhHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«"
      ],
      "metadata": {
        "id": "vezajMZ8KutT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizedEnsemblePredictor:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'rf': RandomForestClassifier(\n",
        "                  n_estimators=120,        # 100â†’120\n",
        "                  max_depth=7,             # 6â†’7\n",
        "                  min_samples_leaf=15,     # 20â†’15\n",
        "                  min_samples_split=30,    # 40â†’30\n",
        "                  max_features=0.6,        # 0.5â†’0.6\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1\n",
        "              ),\n",
        "              'gb': GradientBoostingClassifier(\n",
        "                  n_estimators=80,\n",
        "                  max_depth=4,\n",
        "                  learning_rate=0.1,\n",
        "                  subsample=0.7,\n",
        "                  min_samples_leaf=20,\n",
        "                  random_state=42\n",
        "              ),\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y, term_id):\n",
        "        print(f\"\\nå­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X.shape}\")\n",
        "        print(f\"é™½æ€§ç‡: {y.mean():.4f}\")\n",
        "\n",
        "        # å„ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’\n",
        "        self.models['rf'].fit(X, y)\n",
        "        self.models['gb'].fit(X, y)\n",
        "\n",
        "        # äº¤å·®æ¤œè¨¼ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèª\n",
        "        print(\"\\n=== äº¤å·®æ¤œè¨¼çµæœ ===\")\n",
        "        for name, model in self.models.items():\n",
        "            cv_scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n",
        "            print(f\"{name} - Term {term_id} CV AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿AUCï¼ˆéå­¦ç¿’ãƒã‚§ãƒƒã‚¯ï¼‰\n",
        "            train_pred = model.predict_proba(X)[:, 1]\n",
        "            train_auc = roc_auc_score(y, train_pred)\n",
        "            overfitting_gap = train_auc - cv_scores.mean()\n",
        "            print(f\"  Train AUC: {train_auc:.4f}\")\n",
        "            print(f\"  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: {overfitting_gap:.4f}\")\n",
        "\n",
        "            if overfitting_gap > 0.15:\n",
        "                print(f\"  âš ï¸ éå­¦ç¿’ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ\")\n",
        "            elif overfitting_gap > 0.10:\n",
        "                print(f\"  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\")\n",
        "            else:\n",
        "                print(f\"  âœ… éå­¦ç¿’ã¯æŠ‘åˆ¶ã•ã‚Œã¦ã„ã¾ã™\")\n",
        "\n",
        "    def predict_proba(self, X, term_id):\n",
        "        rf_pred = self.models['rf'].predict_proba(X)[:, 1]\n",
        "        gb_pred = self.models['gb'].predict_proba(X)[:, 1]\n",
        "\n",
        "        # ã‚ˆã‚Šä¿å®ˆçš„ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n",
        "        ensemble_pred = 0.6 * rf_pred + 0.4 * gb_pred\n",
        "        return ensemble_pred"
      ],
      "metadata": {
        "id": "C5wDNgCXKr6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®å¼·åŒ–"
      ],
      "metadata": {
        "id": "iRopblc5K2pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–¢æ•°\n",
        "def evaluate_model_performance(y_true, y_pred_proba, threshold=0.23):\n",
        "    \"\"\"PoCã§è¨­å®šã—ãŸæŒ‡æ¨™ã§è©•ä¾¡\"\"\"\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    metrics = {\n",
        "        'AUC': roc_auc_score(y_true, y_pred_proba),\n",
        "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'F1': f1_score(y_true, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "    print(f\"AUC: {metrics['AUC']:.4f} (ç›®æ¨™: 0.7ä»¥ä¸Š)\")\n",
        "    print(f\"Precision: {metrics['Precision']:.4f} (ç›®æ¨™: 0.4ä»¥ä¸Š)\")\n",
        "    print(f\"Recall: {metrics['Recall']:.4f} (ç›®æ¨™: 0.6ä»¥ä¸Š)\")\n",
        "    print(f\"F1 Score: {metrics['F1']:.4f} (ç›®æ¨™: 0.5ä»¥ä¸Š)\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "sgDwaXdXK1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆæ”¹å–„ç‰ˆï¼‰"
      ],
      "metadata": {
        "id": "-UEuTjAjK-o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_prediction_pipeline(train_df, test_df):\n",
        "    \"\"\"éå­¦ç¿’ã‚’ä¿®æ­£ã—ãŸãƒ¡ã‚¤ãƒ³äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\"\"\"\n",
        "\n",
        "    all_available_columns = [col for col in train_df.columns if col not in ['y'] and not col.startswith('train_term_') and not col.startswith('test_term_')]\n",
        "\n",
        "    feature_columns = [\n",
        "        # Existing features\n",
        "        'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡',\n",
        "        'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month',\n",
        "        'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group',\n",
        "        'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½',\n",
        "        'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡',\n",
        "        'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š',\n",
        "\n",
        "        'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“',\n",
        "        'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡',\n",
        "\n",
        "        'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std',\n",
        "        'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique',\n",
        "        'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§',\n",
        "\n",
        "        'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std',\n",
        "        'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean',\n",
        "        'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦',\n",
        "        'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½'\n",
        "    ]\n",
        "\n",
        "\n",
        "    print(f\"ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(feature_columns)}\")\n",
        "\n",
        "    ensemble_models = {}\n",
        "    y_pred_df = pd.DataFrame()\n",
        "    all_auc_scores = []\n",
        "\n",
        "    for i in range(1, 7):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Term {i} ã®å‡¦ç†\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
        "        train_term = train_df[train_df[f'train_term_{i}'] == 1]\n",
        "        # Ensure that feature_columns only contains columns present in train_term\n",
        "        valid_feature_columns = [col for col in feature_columns if col in train_term.columns]\n",
        "        X_train = train_term[valid_feature_columns]\n",
        "        y_train = train_term['y']\n",
        "\n",
        "        print(f\"Columns in X_train before encoding: {X_train.columns.tolist()}\")\n",
        "\n",
        "\n",
        "        # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
        "        # Ensure columns to encode are present in X_train\n",
        "        categorical_cols = ['æŠ•è³‡æ–¹é‡', 'age_group']\n",
        "        categorical_cols_to_encode = [col for col in categorical_cols if col in X_train.columns]\n",
        "        X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols_to_encode,\n",
        "                                         drop_first=True, dtype=int)\n",
        "\n",
        "\n",
        "        print(f\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: {X_train_encoded.shape[1]}\")\n",
        "        print(f\"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {len(y_train)}, é™½æ€§ç‡: {y_train.mean():.4f}\")\n",
        "\n",
        "        # éå­¦ç¿’å¯¾ç­–æ¸ˆã¿ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
        "        ensemble = OptimizedEnsemblePredictor()\n",
        "        ensemble.fit(X_train_encoded, y_train, i)\n",
        "        ensemble_models[i] = ensemble\n",
        "\n",
        "        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡\n",
        "        train_pred = ensemble.predict_proba(X_train_encoded, i)\n",
        "        print(\"\\n=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\")\n",
        "        metrics = evaluate_model_performance(y_train, train_pred, threshold=0.23)\n",
        "        all_auc_scores.append(metrics['AUC'])\n",
        "\n",
        "        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬\n",
        "        test_term = test_df[test_df[f'test_term_{i}'] == 1]\n",
        "        # Ensure that feature_columns only contains columns present in test_term\n",
        "        valid_feature_columns_test = [col for col in feature_columns if col in test_term.columns]\n",
        "        X_test = test_term[valid_feature_columns_test]\n",
        "        X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols_to_encode, # Use the same columns to encode as train\n",
        "                                         drop_first=True, dtype=int)\n",
        "\n",
        "        # ã‚«ãƒ©ãƒ èª¿æ•´\n",
        "        missing_cols = set(X_train_encoded.columns) - set(X_test_encoded.columns)\n",
        "        for col in missing_cols:\n",
        "            X_test_encoded[col] = 0\n",
        "        X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
        "\n",
        "        # äºˆæ¸¬å®Ÿè¡Œ\n",
        "        test_pred = ensemble.predict_proba(X_test_encoded, i)\n",
        "\n",
        "        # çµæœã‚’DataFrameã«è¿½åŠ \n",
        "        term_results = pd.DataFrame({\n",
        "            'ID': test_term['ID'],\n",
        "            'predict': test_pred\n",
        "        })\n",
        "\n",
        "        if y_pred_df.empty:\n",
        "            y_pred_df = term_results\n",
        "        else:\n",
        "            y_pred_df = pd.concat([y_pred_df, term_results])\n",
        "\n",
        "    # å…¨ä½“ã‚µãƒãƒªãƒ¼\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"éå­¦ç¿’ä¿®æ­£å¾Œã®AUCã‚µãƒãƒªãƒ¼\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for i, auc in enumerate(all_auc_scores, 1):\n",
        "        print(f\"Term {i}: {auc:.4f}\")\n",
        "\n",
        "    avg_auc = np.mean(all_auc_scores)\n",
        "    print(f\"\\nå¹³å‡AUC: {avg_auc:.4f}\")\n",
        "\n",
        "    if avg_auc >= 0.65:\n",
        "        print(\"ğŸ‰ éå­¦ç¿’ä¿®æ­£æˆåŠŸï¼AUC 0.65é”æˆ\")\n",
        "    elif avg_auc >= 0.62:\n",
        "        print(\"ğŸ“ˆ éå­¦ç¿’ãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸ\")\n",
        "    else:\n",
        "        print(f\"ğŸ“Š ç¾åœ¨ã®AUC: {avg_auc:.4f} (éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¢ºèª)\")\n",
        "\n",
        "    return y_pred_df, ensemble_models"
      ],
      "metadata": {
        "id": "TUdXhHeCK7fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œ\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ã‚·ãƒ³ãƒ—ãƒ«äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹\")\n",
        "\n",
        "    # Apply advanced feature engineering\n",
        "    train_df = create_advanced_features_v2(train_df, base_dir)\n",
        "    test_df = create_advanced_features_v2(test_df, base_dir)\n",
        "\n",
        "    print(\"\\n--- Debug: Columns after create_advanced_features_v2 ---\")\n",
        "    print(\"Train_df columns:\", train_df.columns.tolist())\n",
        "    print(\"Test_df columns:\", test_df.columns.tolist())\n",
        "    print(\"--- End Debug ---\")\n",
        "\n",
        "\n",
        "    # äºˆæ¸¬å®Ÿè¡Œ\n",
        "    y_pred_df, models = main_prediction_pipeline(train_df, test_df)\n",
        "\n",
        "    # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆTerm 1ã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰\n",
        "    train_term_1 = train_df[train_df['train_term_1'] == 1]\n",
        "\n",
        "    feature_columns = [\n",
        "        # æ—¢å­˜ç‰¹å¾´é‡ï¼ˆå¤‰æ›´ãªã—ï¼‰\n",
        "        'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡',\n",
        "        'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month',\n",
        "        'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group',\n",
        "        'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½',\n",
        "        'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡',\n",
        "        'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š',\n",
        "\n",
        "        # ã€è¿½åŠ ã€‘æ–°ã—ã„ç‰¹å¾´é‡ï¼ˆ7ã¤ï¼‰\n",
        "        'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“',\n",
        "        'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡'\n",
        "    ]\n",
        "\n",
        "    # Check if the feature_columns are in train_term_1 before selecting\n",
        "    missing_in_train_term_1 = [col for col in feature_columns if col not in train_term_1.columns]\n",
        "    if missing_in_train_term_1:\n",
        "        print(f\"Warning: Missing columns in train_term_1 for feature importance analysis: {missing_in_train_term_1}\")\n",
        "        # Filter feature_columns to only include those present in train_term_1\n",
        "        feature_columns_for_importance = [col for col in feature_columns if col in train_term_1.columns]\n",
        "    else:\n",
        "        feature_columns_for_importance = feature_columns\n",
        "\n",
        "\n",
        "    X_sample = pd.get_dummies(train_term_1[feature_columns_for_importance],\n",
        "                             columns=['æŠ•è³‡æ–¹é‡', 'age_group'], drop_first=True, dtype=int)\n",
        "\n",
        "    if 'analyze_feature_importance' in locals():\n",
        "        importance_df = analyze_feature_importance(models, X_sample.columns)\n",
        "    else:\n",
        "        print(\"Error: analyze_feature_importance function is not defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfl0gesBLDg_",
        "outputId": "1795ef46-cab2-41ac-f4fb-f4ce9b5fd56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ã‚·ãƒ³ãƒ—ãƒ«äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹\n",
            "ğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
            "Debug: customer_behavior columns before merge: ['å–å¼•_å–å¾—ä¾¡é¡_count', 'å–å¼•_å–å¾—ä¾¡é¡_mean', 'å–å¼•_å–å¾—ä¾¡é¡_std', 'å–å¼•_å–å¾—ä¾¡é¡_sum', 'å–å¼•_å£²å´æç›Š_sum', 'å–å¼•_å£²å´æç›Š_mean', 'å–å¼•_å£²å´æç›Š_std', 'å–å¼•_å£²å´æç›Š_count', 'å–å¼•_å„Ÿé‚„æç›Š_sum', 'å–å¼•_å„Ÿé‚„æç›Š_count', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_sum', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_sum', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_sum', 'å–å¼•æœŸé–“_æ—¥æ•°', 'å–å¼•æ—¥æ•°', 'ç·å–å¼•å›æ•°', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡', 'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—']\n",
            "Debug: customer_behavior shape before merge: (872, 31)\n",
            "Debug: df columns before merge: ['ID', 'é¡§å®¢ID', 'ä½æ‰€ã‚³ãƒ¼ãƒ‰', 'é¡§å®¢æ°å', 'åŸºæº–å¹´æœˆ', 'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'train_term_1', 'train_term_2', 'train_term_3', 'train_term_4', 'train_term_5', 'train_term_6', 'ç¿Œæœˆ_è³¼å…¥', 'ç¿Œæœˆ_å£²å´', 'ç¿Œã€…æœˆ_è³¼å…¥', 'ç¿Œã€…æœˆ_å£²å´', 'y', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'è©•ä¾¡å€ç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'è©•ä¾¡æç›Š_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§']\n",
            "Debug: df shape before merge: (90000, 51)\n",
            "Debug: df columns after merge: ['ID', 'é¡§å®¢ID', 'ä½æ‰€ã‚³ãƒ¼ãƒ‰', 'é¡§å®¢æ°å', 'åŸºæº–å¹´æœˆ', 'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'train_term_1', 'train_term_2', 'train_term_3', 'train_term_4', 'train_term_5', 'train_term_6', 'ç¿Œæœˆ_è³¼å…¥', 'ç¿Œæœˆ_å£²å´', 'ç¿Œã€…æœˆ_è³¼å…¥', 'ç¿Œã€…æœˆ_å£²å´', 'y', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'è©•ä¾¡å€ç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'è©•ä¾¡æç›Š_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'å–å¼•_å–å¾—ä¾¡é¡_count', 'å–å¼•_å–å¾—ä¾¡é¡_mean', 'å–å¼•_å–å¾—ä¾¡é¡_std', 'å–å¼•_å–å¾—ä¾¡é¡_sum', 'å–å¼•_å£²å´æç›Š_sum', 'å–å¼•_å£²å´æç›Š_mean', 'å–å¼•_å£²å´æç›Š_std', 'å–å¼•_å£²å´æç›Š_count', 'å–å¼•_å„Ÿé‚„æç›Š_sum', 'å–å¼•_å„Ÿé‚„æç›Š_count', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_sum', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_sum', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_sum', 'å–å¼•æœŸé–“_æ—¥æ•°', 'å–å¼•æ—¥æ•°', 'ç·å–å¼•å›æ•°', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡', 'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—']\n",
            "Debug: df shape after merge: (90000, 82)\n",
            "ğŸ“ˆ å–å¼•è¡Œå‹•ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¾ã—ãŸ\n",
            "ğŸ—ºï¸ åœ°åŸŸç‰¹å¾´é‡ã‚’è¿½åŠ \n",
            "ğŸ“Š ãƒˆãƒ¬ãƒ³ãƒ‰ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
            "Debug: customer_behavior columns before merge: ['å–å¼•_å–å¾—ä¾¡é¡_count', 'å–å¼•_å–å¾—ä¾¡é¡_mean', 'å–å¼•_å–å¾—ä¾¡é¡_std', 'å–å¼•_å–å¾—ä¾¡é¡_sum', 'å–å¼•_å£²å´æç›Š_sum', 'å–å¼•_å£²å´æç›Š_mean', 'å–å¼•_å£²å´æç›Š_std', 'å–å¼•_å£²å´æç›Š_count', 'å–å¼•_å„Ÿé‚„æç›Š_sum', 'å–å¼•_å„Ÿé‚„æç›Š_count', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_sum', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_sum', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_sum', 'å–å¼•æœŸé–“_æ—¥æ•°', 'å–å¼•æ—¥æ•°', 'ç·å–å¼•å›æ•°', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡', 'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—']\n",
            "Debug: customer_behavior shape before merge: (872, 31)\n",
            "Debug: df columns before merge: ['Unnamed: 0', 'ID', 'é¡§å®¢ID', 'ä½æ‰€ã‚³ãƒ¼ãƒ‰', 'é¡§å®¢æ°å', 'åŸºæº–å¹´æœˆ', 'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'test_term_1', 'test_term_2', 'test_term_3', 'test_term_4', 'test_term_5', 'test_term_6', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'è©•ä¾¡å€ç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'è©•ä¾¡æç›Š_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§']\n",
            "Debug: df shape before merge: (6000, 47)\n",
            "Debug: df columns after merge: ['Unnamed: 0', 'ID', 'é¡§å®¢ID', 'ä½æ‰€ã‚³ãƒ¼ãƒ‰', 'é¡§å®¢æ°å', 'åŸºæº–å¹´æœˆ', 'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'test_term_1', 'test_term_2', 'test_term_3', 'test_term_4', 'test_term_5', 'test_term_6', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'è©•ä¾¡å€ç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'è©•ä¾¡æç›Š_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'å–å¼•_å–å¾—ä¾¡é¡_count', 'å–å¼•_å–å¾—ä¾¡é¡_mean', 'å–å¼•_å–å¾—ä¾¡é¡_std', 'å–å¼•_å–å¾—ä¾¡é¡_sum', 'å–å¼•_å£²å´æç›Š_sum', 'å–å¼•_å£²å´æç›Š_mean', 'å–å¼•_å£²å´æç›Š_std', 'å–å¼•_å£²å´æç›Š_count', 'å–å¼•_å„Ÿé‚„æç›Š_sum', 'å–å¼•_å„Ÿé‚„æç›Š_count', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_sum', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_sum', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_sum', 'å–å¼•æœŸé–“_æ—¥æ•°', 'å–å¼•æ—¥æ•°', 'ç·å–å¼•å›æ•°', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡', 'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—']\n",
            "Debug: df shape after merge: (6000, 78)\n",
            "ğŸ“ˆ å–å¼•è¡Œå‹•ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¾ã—ãŸ\n",
            "ğŸ—ºï¸ åœ°åŸŸç‰¹å¾´é‡ã‚’è¿½åŠ \n",
            "\n",
            "--- Debug: Columns after create_advanced_features_v2 ---\n",
            "Train_df columns: ['ID', 'é¡§å®¢ID', 'ä½æ‰€ã‚³ãƒ¼ãƒ‰', 'é¡§å®¢æ°å', 'åŸºæº–å¹´æœˆ', 'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'train_term_1', 'train_term_2', 'train_term_3', 'train_term_4', 'train_term_5', 'train_term_6', 'ç¿Œæœˆ_è³¼å…¥', 'ç¿Œæœˆ_å£²å´', 'ç¿Œã€…æœˆ_è³¼å…¥', 'ç¿Œã€…æœˆ_å£²å´', 'y', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'è©•ä¾¡å€ç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'è©•ä¾¡æç›Š_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'å–å¼•_å–å¾—ä¾¡é¡_count', 'å–å¼•_å–å¾—ä¾¡é¡_mean', 'å–å¼•_å–å¾—ä¾¡é¡_std', 'å–å¼•_å–å¾—ä¾¡é¡_sum', 'å–å¼•_å£²å´æç›Š_sum', 'å–å¼•_å£²å´æç›Š_mean', 'å–å¼•_å£²å´æç›Š_std', 'å–å¼•_å£²å´æç›Š_count', 'å–å¼•_å„Ÿé‚„æç›Š_sum', 'å–å¼•_å„Ÿé‚„æç›Š_count', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_sum', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_sum', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_sum', 'å–å¼•æœŸé–“_æ—¥æ•°', 'å–å¼•æ—¥æ•°', 'ç·å–å¼•å›æ•°', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡', 'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š']\n",
            "Test_df columns: ['Unnamed: 0', 'ID', 'é¡§å®¢ID', 'ä½æ‰€ã‚³ãƒ¼ãƒ‰', 'é¡§å®¢æ°å', 'åŸºæº–å¹´æœˆ', 'å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'test_term_1', 'test_term_2', 'test_term_3', 'test_term_4', 'test_term_5', 'test_term_6', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'è©•ä¾¡å€ç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'è©•ä¾¡æç›Š_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'æŠ•è³‡æ–¹é‡Ã—æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'å–å¼•_å–å¾—ä¾¡é¡_count', 'å–å¼•_å–å¾—ä¾¡é¡_mean', 'å–å¼•_å–å¾—ä¾¡é¡_std', 'å–å¼•_å–å¾—ä¾¡é¡_sum', 'å–å¼•_å£²å´æç›Š_sum', 'å–å¼•_å£²å´æç›Š_mean', 'å–å¼•_å£²å´æç›Š_std', 'å–å¼•_å£²å´æç›Š_count', 'å–å¼•_å„Ÿé‚„æç›Š_sum', 'å–å¼•_å„Ÿé‚„æç›Š_count', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_mean', 'å–å¼•_ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å–å¼•ãƒ•ãƒ©ã‚°_sum', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ã‚´ãƒ¼ãƒ«è¨­å®šå®Ÿæ–½_sum', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_mean', 'å–å¼•_ãƒ­ã‚¹ã‚«ãƒƒãƒˆè¨­å®šå®Ÿæ–½_sum', 'å–å¼•æœŸé–“_æ—¥æ•°', 'å–å¼•æ—¥æ•°', 'ç·å–å¼•å›æ•°', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'å¹³å‡åˆ©ç›Šç‡', 'å–å¼•é »åº¦', 'æ•°å­—æ´»ç”¨åº¦', 'ãƒªã‚¹ã‚¯ç®¡ç†åº¦', 'æŠ•è³‡å®¶ã‚¿ã‚¤ãƒ—', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š']\n",
            "--- End Debug ---\n",
            "ä½¿ç”¨ç‰¹å¾´é‡æ•°: 62\n",
            "\n",
            "============================================================\n",
            "Term 1 ã®å‡¦ç†\n",
            "============================================================\n",
            "Columns in X_train before encoding: ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½']\n",
            "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: 63\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: 80000, é™½æ€§ç‡: 0.1972\n",
            "\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (80000, 63)\n",
            "é™½æ€§ç‡: 0.1972\n",
            "\n",
            "=== äº¤å·®æ¤œè¨¼çµæœ ===\n",
            "rf - Term 1 CV AUC: 0.6157 (+/- 0.0369)\n",
            "  Train AUC: 0.7170\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1013\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "gb - Term 1 CV AUC: 0.6184 (+/- 0.0556)\n",
            "  Train AUC: 0.7377\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1193\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "\n",
            "=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\n",
            "AUC: 0.7328 (ç›®æ¨™: 0.7ä»¥ä¸Š)\n",
            "Precision: 0.2813 (ç›®æ¨™: 0.4ä»¥ä¸Š)\n",
            "Recall: 0.9033 (ç›®æ¨™: 0.6ä»¥ä¸Š)\n",
            "F1 Score: 0.4290 (ç›®æ¨™: 0.5ä»¥ä¸Š)\n",
            "\n",
            "============================================================\n",
            "Term 2 ã®å‡¦ç†\n",
            "============================================================\n",
            "Columns in X_train before encoding: ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½']\n",
            "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: 63\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: 82000, é™½æ€§ç‡: 0.1976\n",
            "\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (82000, 63)\n",
            "é™½æ€§ç‡: 0.1976\n",
            "\n",
            "=== äº¤å·®æ¤œè¨¼çµæœ ===\n",
            "rf - Term 2 CV AUC: 0.6121 (+/- 0.0372)\n",
            "  Train AUC: 0.7168\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1047\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "gb - Term 2 CV AUC: 0.6150 (+/- 0.0566)\n",
            "  Train AUC: 0.7359\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1209\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "\n",
            "=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\n",
            "AUC: 0.7318 (ç›®æ¨™: 0.7ä»¥ä¸Š)\n",
            "Precision: 0.2795 (ç›®æ¨™: 0.4ä»¥ä¸Š)\n",
            "Recall: 0.9071 (ç›®æ¨™: 0.6ä»¥ä¸Š)\n",
            "F1 Score: 0.4273 (ç›®æ¨™: 0.5ä»¥ä¸Š)\n",
            "\n",
            "============================================================\n",
            "Term 3 ã®å‡¦ç†\n",
            "============================================================\n",
            "Columns in X_train before encoding: ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½']\n",
            "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: 63\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: 84000, é™½æ€§ç‡: 0.1980\n",
            "\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (84000, 63)\n",
            "é™½æ€§ç‡: 0.1980\n",
            "\n",
            "=== äº¤å·®æ¤œè¨¼çµæœ ===\n",
            "rf - Term 3 CV AUC: 0.6208 (+/- 0.0658)\n",
            "  Train AUC: 0.7140\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.0932\n",
            "  âœ… éå­¦ç¿’ã¯æŠ‘åˆ¶ã•ã‚Œã¦ã„ã¾ã™\n",
            "gb - Term 3 CV AUC: 0.6263 (+/- 0.0673)\n",
            "  Train AUC: 0.7355\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1093\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "\n",
            "=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\n",
            "AUC: 0.7303 (ç›®æ¨™: 0.7ä»¥ä¸Š)\n",
            "Precision: 0.2806 (ç›®æ¨™: 0.4ä»¥ä¸Š)\n",
            "Recall: 0.9095 (ç›®æ¨™: 0.6ä»¥ä¸Š)\n",
            "F1 Score: 0.4289 (ç›®æ¨™: 0.5ä»¥ä¸Š)\n",
            "\n",
            "============================================================\n",
            "Term 4 ã®å‡¦ç†\n",
            "============================================================\n",
            "Columns in X_train before encoding: ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½']\n",
            "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: 63\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: 86000, é™½æ€§ç‡: 0.1985\n",
            "\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (86000, 63)\n",
            "é™½æ€§ç‡: 0.1985\n",
            "\n",
            "=== äº¤å·®æ¤œè¨¼çµæœ ===\n",
            "rf - Term 4 CV AUC: 0.6117 (+/- 0.0518)\n",
            "  Train AUC: 0.7138\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1021\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "gb - Term 4 CV AUC: 0.6191 (+/- 0.0668)\n",
            "  Train AUC: 0.7363\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1171\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "\n",
            "=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\n",
            "AUC: 0.7305 (ç›®æ¨™: 0.7ä»¥ä¸Š)\n",
            "Precision: 0.2805 (ç›®æ¨™: 0.4ä»¥ä¸Š)\n",
            "Recall: 0.9100 (ç›®æ¨™: 0.6ä»¥ä¸Š)\n",
            "F1 Score: 0.4288 (ç›®æ¨™: 0.5ä»¥ä¸Š)\n",
            "\n",
            "============================================================\n",
            "Term 5 ã®å‡¦ç†\n",
            "============================================================\n",
            "Columns in X_train before encoding: ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½']\n",
            "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: 63\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: 88000, é™½æ€§ç‡: 0.1989\n",
            "\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (88000, 63)\n",
            "é™½æ€§ç‡: 0.1989\n",
            "\n",
            "=== äº¤å·®æ¤œè¨¼çµæœ ===\n",
            "rf - Term 5 CV AUC: 0.6052 (+/- 0.0450)\n",
            "  Train AUC: 0.7132\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1080\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "gb - Term 5 CV AUC: 0.6081 (+/- 0.0582)\n",
            "  Train AUC: 0.7324\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1243\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "\n",
            "=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\n",
            "AUC: 0.7278 (ç›®æ¨™: 0.7ä»¥ä¸Š)\n",
            "Precision: 0.2803 (ç›®æ¨™: 0.4ä»¥ä¸Š)\n",
            "Recall: 0.9061 (ç›®æ¨™: 0.6ä»¥ä¸Š)\n",
            "F1 Score: 0.4282 (ç›®æ¨™: 0.5ä»¥ä¸Š)\n",
            "\n",
            "============================================================\n",
            "Term 6 ã®å‡¦ç†\n",
            "============================================================\n",
            "Columns in X_train before encoding: ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡', 'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'year', 'month', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡', 'quarter', 'is_quarter_end', 'age_group', 'æ™‚ä¾¡ä¾¡é¡_é †ä½', 'è³‡ç”£è¦æ¨¡_é †ä½', 'å¹´é½¢Ã—è³‡ç”£è¦æ¨¡', 'é«˜è³‡ç”£ãƒ•ãƒ©ã‚°', 'å«ã¿æãƒ•ãƒ©ã‚°', 'ã‚·ãƒ‹ã‚¢ãƒ•ãƒ©ã‚°', 'æ ªå¼çµŒé¨“ã‚ã‚Š', 'éå»å–å¼•å›æ•°', 'éå»ç´¯ç©æç›Š', 'æŠ•è³‡æˆåŠŸä½“é¨“', 'é¡§å®¢å¹³å‡æ™‚ä¾¡ä¾¡é¡', 'é¡§å®¢è¨˜éŒ²æ•°', 'é¡§å®¢è³‡ç”£å¤‰å‹•', 'ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡_first', 'æ™‚ä¾¡ä¾¡é¡_last', 'æ™‚ä¾¡ä¾¡é¡_std', 'è³‡ç”£è¦æ¨¡_first', 'è³‡ç”£è¦æ¨¡_last', 'è³‡ç”£è¦æ¨¡_std', 'è©•ä¾¡æç›Š_first', 'è©•ä¾¡æç›Š_last', 'è©•ä¾¡æç›Š_std', 'åŸºæº–å¹´æœˆ_count', 'åŸºæº–å¹´æœˆ_nunique', 'æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡', 'è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡', 'æç›Š_å¤‰åŒ–ç‡', 'æ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°', 'è³‡ç”£_å®‰å®šæ€§', 'åœ°åŸŸ_y_mean', 'åœ°åŸŸ_y_sum', 'åœ°åŸŸ_y_count', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_mean', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_median', 'åœ°åŸŸ_æ™‚ä¾¡ä¾¡é¡_std', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_mean', 'åœ°åŸŸ_è³‡ç”£è¦æ¨¡_median', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_mean', 'åœ°åŸŸ_é¡§å®¢å¹´é½¢_std', 'åœ°åŸŸ_æŠ•è³‡æ–¹é‡_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_mean', 'åœ°åŸŸ_è©•ä¾¡æç›Š_std', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦', 'åœ°åŸŸ_å¯Œè£•åº¦', 'åœ°åŸŸ_å®‰å®šåº¦', 'åœ°åŸŸ_æˆç†Ÿåº¦', 'åœ°åŸŸ_å–å¼•æ´»ç™ºåº¦_é †ä½', 'åœ°åŸŸ_å¯Œè£•åº¦_é †ä½']\n",
            "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œç‰¹å¾´é‡æ•°: 63\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: 90000, é™½æ€§ç‡: 0.1989\n",
            "\n",
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (90000, 63)\n",
            "é™½æ€§ç‡: 0.1989\n",
            "\n",
            "=== äº¤å·®æ¤œè¨¼çµæœ ===\n",
            "rf - Term 6 CV AUC: 0.6134 (+/- 0.0370)\n",
            "  Train AUC: 0.7119\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.0984\n",
            "  âœ… éå­¦ç¿’ã¯æŠ‘åˆ¶ã•ã‚Œã¦ã„ã¾ã™\n",
            "gb - Term 6 CV AUC: 0.6240 (+/- 0.0337)\n",
            "  Train AUC: 0.7336\n",
            "  éå­¦ç¿’ã‚®ãƒ£ãƒƒãƒ—: 0.1096\n",
            "  ğŸ“Š è»½åº¦ã®éå­¦ç¿’\n",
            "\n",
            "=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===\n",
            "AUC: 0.7284 (ç›®æ¨™: 0.7ä»¥ä¸Š)\n",
            "Precision: 0.2800 (ç›®æ¨™: 0.4ä»¥ä¸Š)\n",
            "Recall: 0.9069 (ç›®æ¨™: 0.6ä»¥ä¸Š)\n",
            "F1 Score: 0.4278 (ç›®æ¨™: 0.5ä»¥ä¸Š)\n",
            "\n",
            "============================================================\n",
            "éå­¦ç¿’ä¿®æ­£å¾Œã®AUCã‚µãƒãƒªãƒ¼\n",
            "============================================================\n",
            "Term 1: 0.7328\n",
            "Term 2: 0.7318\n",
            "Term 3: 0.7303\n",
            "Term 4: 0.7305\n",
            "Term 5: 0.7278\n",
            "Term 6: 0.7284\n",
            "\n",
            "å¹³å‡AUC: 0.7302\n",
            "ğŸ‰ éå­¦ç¿’ä¿®æ­£æˆåŠŸï¼AUC 0.65é”æˆ\n",
            "Error: analyze_feature_importance function is not defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©³ç´°åˆ†æ\n",
        "\n",
        "def detailed_performance_analysis(train_df, models):\n",
        "    \"\"\"å„Termã®è©³ç´°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ\"\"\"\n",
        "\n",
        "    results_summary = []\n",
        "\n",
        "    for term_id in range(1, 7):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Term {term_id} è©³ç´°åˆ†æ\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
        "        train_term = train_df[train_df[f'train_term_{term_id}'] == 1]\n",
        "\n",
        "        # åŸºæœ¬çµ±è¨ˆ\n",
        "        print(f\"ãƒ‡ãƒ¼ã‚¿æ•°: {len(train_term)}\")\n",
        "        print(f\"é™½æ€§ç‡: {train_term['y'].mean():.4f}\")\n",
        "        print(f\"é™½æ€§æ•°: {train_term['y'].sum()}\")\n",
        "        print(f\"é™°æ€§æ•°: {(train_term['y'] == 0).sum()}\")\n",
        "\n",
        "        # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡åº¦\n",
        "        imbalance_ratio = (train_term['y'] == 0).sum() / train_term['y'].sum()\n",
        "        print(f\"ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
        "        feature_columns = ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š', 'æŠ•è³‡æ–¹é‡',\n",
        "                          'é¡§å®¢å¹´é½¢', 'æŠ•è³‡çµŒé¨“ï¼ˆæ ªå¼ï¼‰', 'è³‡ç”£è¦æ¨¡', 'å«ã¿æç›Šç‡']\n",
        "\n",
        "        missing_info = {}\n",
        "        for col in feature_columns:\n",
        "            if col in train_term.columns:\n",
        "                missing_pct = train_term[col].isnull().mean() * 100\n",
        "                missing_info[col] = missing_pct\n",
        "                if missing_pct > 5:\n",
        "                    print(f\"âš ï¸ {col}: {missing_pct:.1f}% æ¬ æ\")\n",
        "\n",
        "        # ç‰¹å¾´é‡ã®åˆ†å¸ƒãƒã‚§ãƒƒã‚¯\n",
        "        outlier_info = {}\n",
        "        for col in ['å–å¾—ä¾¡é¡', 'æ™‚ä¾¡ä¾¡é¡', 'è©•ä¾¡æç›Š']:\n",
        "            if col in train_term.columns:\n",
        "                Q1 = train_term[col].quantile(0.25)\n",
        "                Q3 = train_term[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                outliers = ((train_term[col] < Q1 - 1.5*IQR) |\n",
        "                           (train_term[col] > Q3 + 1.5*IQR)).sum()\n",
        "                outlier_pct = outliers / len(train_term) * 100\n",
        "                outlier_info[col] = outlier_pct\n",
        "                if outlier_pct > 10:\n",
        "                    print(f\"ğŸ“Š {col}: {outlier_pct:.1f}% å¤–ã‚Œå€¤\")\n",
        "\n",
        "        results_summary.append({\n",
        "            'term': term_id,\n",
        "            'data_count': len(train_term),\n",
        "            'positive_rate': train_term['y'].mean(),\n",
        "            'imbalance_ratio': imbalance_ratio,\n",
        "            'missing_issues': len([k for k, v in missing_info.items() if v > 5]),\n",
        "            'outlier_issues': len([k for k, v in outlier_info.items() if v > 10])\n",
        "        })\n",
        "\n",
        "    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"å…¨Term ã‚µãƒãƒªãƒ¼\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    summary_df = pd.DataFrame(results_summary)\n",
        "    display(summary_df)\n",
        "\n",
        "    # å•é¡Œã®ã‚ã‚‹Termã‚’ç‰¹å®š\n",
        "    problem_terms = []\n",
        "    for _, row in summary_df.iterrows():\n",
        "        issues = []\n",
        "        if row['positive_rate'] < 0.05:\n",
        "            issues.append(\"æ¥µåº¦ã®ä¸å‡è¡¡\")\n",
        "        if row['imbalance_ratio'] > 50:\n",
        "            issues.append(\"é‡åº¦ã®ä¸å‡è¡¡\")\n",
        "        if row['missing_issues'] > 0:\n",
        "            issues.append(\"æ¬ æå€¤å•é¡Œ\")\n",
        "        if row['outlier_issues'] > 0:\n",
        "            issues.append(\"å¤–ã‚Œå€¤å•é¡Œ\")\n",
        "\n",
        "        if issues:\n",
        "            problem_terms.append(f\"Term {row['term']}: {', '.join(issues)}\")\n",
        "\n",
        "    if problem_terms:\n",
        "        print(\"\\nğŸš¨ è¦æ³¨æ„Term:\")\n",
        "        for problem in problem_terms:\n",
        "            print(f\"  {problem}\")\n",
        "    else:\n",
        "        print(\"\\nâœ… å…¨Termã§ãƒ‡ãƒ¼ã‚¿å“è³ªã¯è‰¯å¥½\")\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "# ç‰¹å¾´é‡é‡è¦åº¦ã®è©³ç´°åˆ†æ\n",
        "def analyze_feature_importance_detailed(models):\n",
        "    \"\"\"ç‰¹å¾´é‡é‡è¦åº¦ã®è©³ç´°åˆ†æ\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Term1ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ï¼‰\n",
        "    if 1 in models:\n",
        "        rf_model = models[1].models['rf']\n",
        "        gb_model = models[1].models['gb']\n",
        "\n",
        "        # Get feature names from the trained model\n",
        "        feature_names = rf_model.feature_names_in_\n",
        "\n",
        "        rf_importance = rf_model.feature_importances_\n",
        "        gb_importance = gb_model.feature_importances_\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'rf_importance': rf_importance,\n",
        "            'gb_importance': gb_importance\n",
        "        })\n",
        "\n",
        "        importance_df['avg_importance'] = (importance_df['rf_importance'] +\n",
        "                                         importance_df['gb_importance']) / 2\n",
        "        importance_df = importance_df.sort_values('avg_importance', ascending=False)\n",
        "\n",
        "        print(\"Top 15 é‡è¦ç‰¹å¾´é‡:\")\n",
        "        display(importance_df.head(15)[['feature', 'avg_importance']].to_string(index=False))\n",
        "\n",
        "        # ä½é‡è¦åº¦ç‰¹å¾´é‡ï¼ˆå‰Šé™¤å€™è£œï¼‰\n",
        "        low_importance = importance_df[importance_df['avg_importance'] < 0.01]\n",
        "        print(f\"\\nå‰Šé™¤å€™è£œç‰¹å¾´é‡ï¼ˆé‡è¦åº¦ < 0.01ï¼‰: {len(low_importance)}å€‹\")\n",
        "        if len(low_importance) > 0:\n",
        "            display(low_importance[['feature', 'avg_importance']].head(10).to_string(index=False))\n",
        "\n",
        "        return importance_df\n",
        "    else:\n",
        "        print(\"ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "        return None\n",
        "\n",
        "# å®Ÿè¡Œä¾‹ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼‰\n",
        "# summary_df = detailed_performance_analysis(train_df, models)\n",
        "# importance_df = analyze_feature_importance_detailed(models, X_sample.columns)"
      ],
      "metadata": {
        "id": "3WlRT_b3c2Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ\n",
        "summary_df = detailed_performance_analysis(train_df, models)\n",
        "\n",
        "# ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ\n",
        "importance_df = analyze_feature_importance_detailed(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ma84EU-Xn-M_",
        "outputId": "02904643-6451-4937-dc5c-7217363c0698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Term 1 è©³ç´°åˆ†æ\n",
            "==================================================\n",
            "ãƒ‡ãƒ¼ã‚¿æ•°: 80000\n",
            "é™½æ€§ç‡: 0.1972\n",
            "é™½æ€§æ•°: 15778\n",
            "é™°æ€§æ•°: 64222\n",
            "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: 4.07:1\n",
            "ğŸ“Š è©•ä¾¡æç›Š: 16.7% å¤–ã‚Œå€¤\n",
            "\n",
            "==================================================\n",
            "Term 2 è©³ç´°åˆ†æ\n",
            "==================================================\n",
            "ãƒ‡ãƒ¼ã‚¿æ•°: 82000\n",
            "é™½æ€§ç‡: 0.1976\n",
            "é™½æ€§æ•°: 16204\n",
            "é™°æ€§æ•°: 65796\n",
            "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: 4.06:1\n",
            "ğŸ“Š è©•ä¾¡æç›Š: 16.6% å¤–ã‚Œå€¤\n",
            "\n",
            "==================================================\n",
            "Term 3 è©³ç´°åˆ†æ\n",
            "==================================================\n",
            "ãƒ‡ãƒ¼ã‚¿æ•°: 84000\n",
            "é™½æ€§ç‡: 0.1980\n",
            "é™½æ€§æ•°: 16635\n",
            "é™°æ€§æ•°: 67365\n",
            "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: 4.05:1\n",
            "ğŸ“Š è©•ä¾¡æç›Š: 16.4% å¤–ã‚Œå€¤\n",
            "\n",
            "==================================================\n",
            "Term 4 è©³ç´°åˆ†æ\n",
            "==================================================\n",
            "ãƒ‡ãƒ¼ã‚¿æ•°: 86000\n",
            "é™½æ€§ç‡: 0.1985\n",
            "é™½æ€§æ•°: 17067\n",
            "é™°æ€§æ•°: 68933\n",
            "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: 4.04:1\n",
            "ğŸ“Š è©•ä¾¡æç›Š: 16.3% å¤–ã‚Œå€¤\n",
            "\n",
            "==================================================\n",
            "Term 5 è©³ç´°åˆ†æ\n",
            "==================================================\n",
            "ãƒ‡ãƒ¼ã‚¿æ•°: 88000\n",
            "é™½æ€§ç‡: 0.1989\n",
            "é™½æ€§æ•°: 17500\n",
            "é™°æ€§æ•°: 70500\n",
            "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: 4.03:1\n",
            "ğŸ“Š è©•ä¾¡æç›Š: 16.1% å¤–ã‚Œå€¤\n",
            "\n",
            "==================================================\n",
            "Term 6 è©³ç´°åˆ†æ\n",
            "==================================================\n",
            "ãƒ‡ãƒ¼ã‚¿æ•°: 90000\n",
            "é™½æ€§ç‡: 0.1989\n",
            "é™½æ€§æ•°: 17899\n",
            "é™°æ€§æ•°: 72101\n",
            "ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡æ¯”: 4.03:1\n",
            "ğŸ“Š è©•ä¾¡æç›Š: 16.0% å¤–ã‚Œå€¤\n",
            "\n",
            "============================================================\n",
            "å…¨Term ã‚µãƒãƒªãƒ¼\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   term  data_count  positive_rate  imbalance_ratio  missing_issues  \\\n",
              "0     1       80000       0.197225         4.070351               0   \n",
              "1     2       82000       0.197610         4.060479               0   \n",
              "2     3       84000       0.198036         4.049594               0   \n",
              "3     4       86000       0.198453         4.038964               0   \n",
              "4     5       88000       0.198864         4.028571               0   \n",
              "5     6       90000       0.198878         4.028214               0   \n",
              "\n",
              "   outlier_issues  \n",
              "0               1  \n",
              "1               1  \n",
              "2               1  \n",
              "3               1  \n",
              "4               1  \n",
              "5               1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-594c7769-e60e-4286-9485-374b6cdced0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>data_count</th>\n",
              "      <th>positive_rate</th>\n",
              "      <th>imbalance_ratio</th>\n",
              "      <th>missing_issues</th>\n",
              "      <th>outlier_issues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>80000</td>\n",
              "      <td>0.197225</td>\n",
              "      <td>4.070351</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>82000</td>\n",
              "      <td>0.197610</td>\n",
              "      <td>4.060479</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>84000</td>\n",
              "      <td>0.198036</td>\n",
              "      <td>4.049594</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>86000</td>\n",
              "      <td>0.198453</td>\n",
              "      <td>4.038964</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>88000</td>\n",
              "      <td>0.198864</td>\n",
              "      <td>4.028571</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>90000</td>\n",
              "      <td>0.198878</td>\n",
              "      <td>4.028214</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-594c7769-e60e-4286-9485-374b6cdced0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-594c7769-e60e-4286-9485-374b6cdced0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-594c7769-e60e-4286-9485-374b6cdced0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb459434-91ee-45de-8578-ee48186c5cc5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb459434-91ee-45de-8578-ee48186c5cc5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb459434-91ee-45de-8578-ee48186c5cc5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"importance_df = analyze_feature_importance_detailed(models)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"term\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3741,\n        \"min\": 80000,\n        \"max\": 90000,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          80000,\n          82000,\n          90000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006763185952553546,\n        \"min\": 0.197225,\n        \"max\": 0.19887777777777776,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.197225,\n          0.19760975609756098,\n          0.19887777777777776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imbalance_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017234469750759984,\n        \"min\": 4.028213866696463,\n        \"max\": 4.070351121815186,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.070351121815186,\n          4.060478894100222,\n          4.028213866696463\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_issues\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"outlier_issues\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš¨ è¦æ³¨æ„Term:\n",
            "  Term 1.0: å¤–ã‚Œå€¤å•é¡Œ\n",
            "  Term 2.0: å¤–ã‚Œå€¤å•é¡Œ\n",
            "  Term 3.0: å¤–ã‚Œå€¤å•é¡Œ\n",
            "  Term 4.0: å¤–ã‚Œå€¤å•é¡Œ\n",
            "  Term 5.0: å¤–ã‚Œå€¤å•é¡Œ\n",
            "  Term 6.0: å¤–ã‚Œå€¤å•é¡Œ\n",
            "\n",
            "============================================================\n",
            "ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ\n",
            "============================================================\n",
            "Top 15 é‡è¦ç‰¹å¾´é‡:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' feature  avg_importance\\n    æ™‚ä¾¡ä¾¡é¡        0.316366\\n æ™‚ä¾¡ä¾¡é¡_é †ä½        0.254873\\n å¹´é½¢Ã—è³‡ç”£è¦æ¨¡        0.096884\\n  éå»å–å¼•å›æ•°        0.076896\\n    è³‡ç”£è¦æ¨¡        0.028906\\n    å–å¾—ä¾¡é¡        0.025357\\n è³‡ç”£è¦æ¨¡_é †ä½        0.022657\\n   å«ã¿æç›Šç‡        0.017532\\n    è©•ä¾¡æç›Š        0.013338\\n    year        0.010733\\nè©•ä¾¡æç›Š_std        0.010666\\n  æç›Š_å¤‰åŒ–ç‡        0.009611\\næ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡        0.006958\\nè³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡        0.006803\\n  è³‡ç”£_å®‰å®šæ€§        0.006494'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "å‰Šé™¤å€™è£œç‰¹å¾´é‡ï¼ˆé‡è¦åº¦ < 0.01ï¼‰: 52å€‹\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'  feature  avg_importance\\n   æç›Š_å¤‰åŒ–ç‡        0.009611\\n æ™‚ä¾¡ä¾¡é¡_å¤‰åŒ–ç‡        0.006958\\n è³‡ç”£è¦æ¨¡_å¤‰åŒ–ç‡        0.006803\\n   è³‡ç”£_å®‰å®šæ€§        0.006494\\n   éå»ç´¯ç©æç›Š        0.006301\\næ™‚ä¾¡ä¾¡é¡_å¤‰å‹•ä¿‚æ•°        0.005800\\nè³‡ç”£è¦æ¨¡_last        0.005652\\n   ç›¸å¯¾æ™‚ä¾¡ä¾¡é¡        0.005543\\næ™‚ä¾¡ä¾¡é¡_last        0.005154\\n     é¡§å®¢å¹´é½¢        0.004657'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
        "submission_df[1] = y_pred_df['predict']\n",
        "submission_df.to_csv('improved_submission.csv', index=False, header=False)\n",
        "\n",
        "print(\"\\næå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ« 'improved_submission.csv' ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\")\n",
        "print(\"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆã«æå‡ºã—ã¦ãã ã•ã„ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMqCAoZVPyUG",
        "outputId": "da01c0b0-c6e6-4496-9b38-666f361d0bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ« 'improved_submission.csv' ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n",
            "ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆã«æå‡ºã—ã¦ãã ã•ã„ã€‚\n"
          ]
        }
      ]
    }
  ]
}